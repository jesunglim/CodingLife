{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77fc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, optim \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T, datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8552c6e",
   "metadata": {},
   "source": [
    "# Transforms and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd78aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b186a8de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4876\\4059288913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/mnist-dataset-pytorch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/mnist-dataset-pytorch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset not found. You can use download=True to download it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "trainset = datasets.MNIST('../input/mnist-dataset-pytorch', train = True, transform = transform)\n",
    "testset = datasets.MNIST('../input/mnist-dataset-pytorch', train = False, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5414f",
   "metadata": {},
   "source": [
    "# ArcFace CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203abaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFace(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_features,out_features,margin = 0.7 ,scale = 64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.FloatTensor(out_features,in_features))\n",
    "        nn.init.xavier_normal_(self.weights)\n",
    "        \n",
    "    def forward(self,features,targets):\n",
    "        cos_theta = F.linear(features,F.normalize(self.weights),bias=None)\n",
    "        cos_theta = cos_theta.clip(-1+1e-7, 1-1e-7)\n",
    "        \n",
    "        arc_cos = torch.acos(cos_theta)\n",
    "        M = F.one_hot(targets, num_classes = self.out_features) * self.margin\n",
    "        arc_cos = arc_cos + M\n",
    "        \n",
    "        cos_theta_2 = torch.cos(arc_cos)\n",
    "        logits = cos_theta_2 * self.scale\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "class MNIST_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNIST_Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50,3)\n",
    "        self.arc_face = ArcFace(in_features = 3, out_features = 10)\n",
    "        \n",
    "    def forward(self,features,targets = None):\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(features), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        _,c,h,w = x.shape\n",
    "        x = x.view(-1, c*h*w)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.normalize(self.fc2(x))\n",
    "        \n",
    "        if targets is not None:\n",
    "            logits = self.arc_face(x,targets)\n",
    "            return logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ca34c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel():\n",
    "    \n",
    "    def __init__(self,criterion = None,optimizer = None,schedular = None,device = None):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.schedular = schedular\n",
    "        self.device = device\n",
    "        \n",
    "    def accuracy(self,logits,labels):\n",
    "        ps = torch.argmax(logits,dim = 1).detach().cpu().numpy()\n",
    "        acc = accuracy_score(ps,labels.detach().cpu().numpy())\n",
    "        return acc\n",
    "\n",
    "    def get_dataloader(self,trainset,validset):\n",
    "        trainloader = DataLoader(trainset,batch_size = 64, num_workers = 4, pin_memory = True)\n",
    "        validloader = DataLoader(validset,batch_size = 64, num_workers = 4, pin_memory = True)\n",
    "        return trainloader, validloader\n",
    "        \n",
    "    def train_batch_loop(self,model,trainloader,i):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        pbar_train = tqdm(trainloader, desc = \"Epoch\" + \" [TRAIN] \" + str(i+1))\n",
    "        \n",
    "        for t,data in enumerate(pbar_train):\n",
    "            \n",
    "            images,labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(images,labels)\n",
    "            loss = self.criterion(logits,labels)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += self.accuracy(logits,labels)\n",
    "            \n",
    "            pbar_train.set_postfix({'loss' : '%.6f' %float(epoch_loss/(t+1)), 'acc' : '%.6f' %float(epoch_acc/(t+1))})\n",
    "            \n",
    "        return epoch_loss / len(trainloader), epoch_acc / len(trainloader)\n",
    "            \n",
    "    \n",
    "    def valid_batch_loop(self,model,validloader,i):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        pbar_valid = tqdm(validloader, desc = \"Epoch\" + \" [VALID] \" + str(i+1))\n",
    "        \n",
    "        for v,data in enumerate(pbar_valid):\n",
    "            \n",
    "            images,labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(images,labels)\n",
    "            loss = self.criterion(logits,labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += self.accuracy(logits,labels)\n",
    "            \n",
    "            pbar_valid.set_postfix({'loss' : '%.6f' %float(epoch_loss/(v+1)), 'acc' : '%.6f' %float(epoch_acc/(v+1))})\n",
    "            \n",
    "        return epoch_loss / len(validloader), epoch_acc / len(validloader)\n",
    "            \n",
    "    \n",
    "    def run(self,model,trainset,validset,epochs):\n",
    "    \n",
    "        trainloader,validloader = self.get_dataloader(trainset,validset)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            model.train()\n",
    "            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader,i)\n",
    "            \n",
    "            model.eval()\n",
    "            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader,i)\n",
    "            \n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "model = TrainModel(criterion, optimizer, device).run(model, trainset, testset, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ad9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = []\n",
    "y = []\n",
    "\n",
    "testloader = DataLoader(testset,batch_size = 64)\n",
    "with torch.no_grad():\n",
    "    for images,labels in tqdm(testloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        embeddings = model(images)\n",
    "        \n",
    "        emb += [embeddings.detach().cpu()]\n",
    "        y += [labels]\n",
    "        \n",
    "    embs = torch.cat(emb).cpu().numpy()\n",
    "    y = torch.cat(y).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(\n",
    "    np.column_stack((embs, y)),\n",
    "    columns = [\"x\",\"y\",\"z\",\"targets\"]\n",
    ")\n",
    "\n",
    "fig = px.scatter_3d(tsne_df, x='x', y='y', z='z',\n",
    "              color='targets')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
