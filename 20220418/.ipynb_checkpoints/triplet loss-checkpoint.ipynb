{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74336e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38c80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ddbaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_path = \"E:\\\\left\\\\left\\\\\"\n",
    "positive_images_path = \"E:\\\\right\\\\right\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f86aa1",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d0324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, target_shape)\n",
    "    return image\n",
    "\n",
    "def preprocess_triplets(anchor, positive, negative):\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(nagative),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0693baef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m anchor_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m----> 2\u001b[0m     [\u001b[38;5;28mstr\u001b[39m(anchor_images_path \u001b[38;5;241m/\u001b[39m f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(anchor_images_path)]\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m positive_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m      6\u001b[0m     [\u001b[38;5;28mstr\u001b[39m(positive_images_path \u001b[38;5;241m/\u001b[39m f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(positive_images_path)]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m image_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(anchor_images)\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m anchor_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m----> 2\u001b[0m     [\u001b[38;5;28mstr\u001b[39m(\u001b[43manchor_images_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(anchor_images_path)]\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m positive_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m      6\u001b[0m     [\u001b[38;5;28mstr\u001b[39m(positive_images_path \u001b[38;5;241m/\u001b[39m f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(positive_images_path)]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m image_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(anchor_images)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "anchor_images = sorted(\n",
    "    [str(anchor_images_path / f) for f in os.listdir(anchor_images_path)]\n",
    ")\n",
    "\n",
    "positive_images = sorted(\n",
    "    [str(positive_images_path / f) for f in os.listdir(positive_images_path)]\n",
    ")\n",
    "\n",
    "image_count = len(anchor_images)\n",
    "\n",
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "\n",
    "# To generate the list of negative images, let's randomize the list of\n",
    "# available images and concatenate them together.\n",
    "rng = np.random.RandomState(seed=42)\n",
    "rng.shuffle(anchor_images)\n",
    "rng.shuffle(positive_images)\n",
    "\n",
    "negative_images = anchor_images + positive_images\n",
    "np.random.RandomState(seed=32).shuffle(negative_images)\n",
    "\n",
    "negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "negative_dataset = negative_dataset.shuffle(buffer_size=4096)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocess_triplets)\n",
    "\n",
    "# Let's now split our dataset in train and validation.\n",
    "train_dataset = dataset.take(round(image_count * 0.8))\n",
    "val_dataset = dataset.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset = train_dataset.batch(32, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "val_dataset = val_dataset.batch(32, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c3811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c6c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214145fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0581ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a4e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba6c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d485f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692c27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
